{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Generator checkpoint: 774000-G\n",
      "Generated spectrograms for conditions: ['p558_p547_p558_001.npy_R', 'p558_p547_p558_001.npy_F', 'p558_p547_p558_001.npy_U', 'p558_p547_p558_001.npy_FU', 'p558_p547_p558_001.npy_RF', 'p558_p547_p558_001.npy_RU', 'p558_p547_p558_001.npy_RFU']\n",
      "Generating waveform for p558_p547_p558_001.npy_R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 30976/30976 [02:56<00:00, 175.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating waveform for p558_p547_p558_001.npy_F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 34560/34560 [03:17<00:00, 175.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating waveform for p558_p547_p558_001.npy_U\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 34560/34560 [03:16<00:00, 175.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating waveform for p558_p547_p558_001.npy_FU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 34560/34560 [03:18<00:00, 173.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating waveform for p558_p547_p558_001.npy_RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 30976/30976 [02:56<00:00, 175.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating waveform for p558_p547_p558_001.npy_RU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 30976/30976 [02:56<00:00, 175.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating waveform for p558_p547_p558_001.npy_RFU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 30976/30976 [02:57<00:00, 174.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in directory: results/774000-G\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import soundfile\n",
    "\n",
    "from hparams import hparams\n",
    "from utils import pad_seq_to_2, quantize_f0_numpy\n",
    "from model import Generator_3 as Generator\n",
    "from synthesis import build_model, wavegen\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# -------------------------\n",
    "# Load Demo Metadata (shared across checkpoints)\n",
    "# -------------------------\n",
    "metadata_path = 'assets/demo_m2f.pkl'\n",
    "with open(metadata_path, \"rb\") as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "# -------------------------\n",
    "# Load Waveform Synthesis Model (shared across checkpoints)\n",
    "# -------------------------\n",
    "synth_model = build_model().to(device)\n",
    "synth_ckpt = torch.load(\"assets/checkpoint_step001000000_ema.pth\", map_location=torch.device(device))\n",
    "synth_model.load_state_dict(synth_ckpt[\"state_dict\"])\n",
    "\n",
    "# -------------------------\n",
    "# List of Generator checkpoint names to process\n",
    "# (without extension, e.g., \"800000-G-B10\")\n",
    "# -------------------------\n",
    "generator_ckpts = [\"774000-G\"]  # update this list as needed\n",
    "\n",
    "# -------------------------\n",
    "# Main processing loop\n",
    "# -------------------------\n",
    "for ckpt_name in generator_ckpts:\n",
    "    print(f\"Processing Generator checkpoint: {ckpt_name}\")\n",
    "    \n",
    "    # Create a dedicated results directory for this checkpoint\n",
    "    results_dir = os.path.join(\"results\", ckpt_name)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # -------------------------\n",
    "    # Load Generator Model & Checkpoint\n",
    "    # -------------------------\n",
    "    G = Generator(hparams).eval().to(device)\n",
    "    g_ckpt_path = os.path.join(\"assets\", f\"{ckpt_name}.ckpt\")\n",
    "    g_checkpoint = torch.load(g_ckpt_path, map_location=lambda storage, loc: storage)\n",
    "    G.load_state_dict(g_checkpoint['model'], strict=False)\n",
    "    \n",
    "    # -------------------------\n",
    "    # Process Source Utterance (sbmt_i)\n",
    "    # -------------------------\n",
    "    sbmt_i = metadata[0]\n",
    "    emb_org = torch.from_numpy(sbmt_i[1]).to(device)\n",
    "    if emb_org.dim() == 1:\n",
    "        emb_org = emb_org.unsqueeze(0)\n",
    "\n",
    "    x_org, f0_org, len_org, uid_org = sbmt_i[2]\n",
    "    # Crop x_org (and f0_org for 1D case) to 192 frames if needed\n",
    "    if x_org.shape[0] > 192:\n",
    "        x_org = x_org[:192, :]\n",
    "        len_org = 192\n",
    "    if f0_org.ndim == 1 and f0_org.shape[0] > 192:\n",
    "        f0_org = f0_org[:192]\n",
    "        \n",
    "    uttr_org_pad, _ = pad_seq_to_2(x_org[np.newaxis, :, :], 192)\n",
    "    uttr_org_pad = torch.from_numpy(uttr_org_pad).to(device)\n",
    "\n",
    "    if f0_org.ndim == 1:\n",
    "        f0_org_pad = np.pad(f0_org, (0, 192 - len_org), 'constant', constant_values=(0, 0))\n",
    "        f0_org_quantized = quantize_f0_numpy(f0_org_pad)[0]\n",
    "    else:\n",
    "        if f0_org.shape[0] < 192:\n",
    "            f0_org_quantized = np.pad(f0_org, ((0, 192 - f0_org.shape[0]), (0, 0)),\n",
    "                                       'constant', constant_values=(0, 0))\n",
    "        else:\n",
    "            f0_org_quantized = f0_org[:192, :]\n",
    "    f0_org_onehot = f0_org_quantized[np.newaxis, :, :]\n",
    "    f0_org_onehot = torch.from_numpy(f0_org_onehot).to(device)\n",
    "    uttr_f0_org = torch.cat((uttr_org_pad, f0_org_onehot), dim=-1)\n",
    "    \n",
    "    # -------------------------\n",
    "    # Process Target Utterance (sbmt_j)\n",
    "    # -------------------------\n",
    "    sbmt_j = metadata[1]\n",
    "    emb_trg = torch.from_numpy(sbmt_j[1]).to(device)\n",
    "    if emb_trg.dim() == 1:\n",
    "        emb_trg = emb_trg.unsqueeze(0)\n",
    "        \n",
    "    x_trg, f0_trg, len_trg, uid_trg = sbmt_j[2]\n",
    "    if x_trg.shape[0] > 192:\n",
    "        x_trg = x_trg[:192, :]\n",
    "        len_trg = 192\n",
    "    if f0_trg.ndim == 1 and f0_trg.shape[0] > 192:\n",
    "        f0_trg = f0_trg[:192]\n",
    "        \n",
    "    uttr_trg_pad, _ = pad_seq_to_2(x_trg[np.newaxis, :, :], 192)\n",
    "    uttr_trg_pad = torch.from_numpy(uttr_trg_pad).to(device)\n",
    "\n",
    "    if f0_trg.ndim == 1:\n",
    "        f0_trg_pad = np.pad(f0_trg, (0, 192 - len_trg), 'constant', constant_values=(0, 0))\n",
    "        f0_trg_quantized = quantize_f0_numpy(f0_trg_pad)[0]\n",
    "    else:\n",
    "        if f0_trg.shape[0] < 192:\n",
    "            f0_trg_quantized = np.pad(f0_trg, ((0, 192 - f0_trg.shape[0]), (0, 0)),\n",
    "                                       'constant', constant_values=(0, 0))\n",
    "        else:\n",
    "            f0_trg_quantized = f0_trg[:192, :]\n",
    "    f0_trg_onehot = f0_trg_quantized[np.newaxis, :, :]\n",
    "    f0_trg_onehot = torch.from_numpy(f0_trg_onehot).to(device)\n",
    "    \n",
    "    # Instead of using an F0 converter, directly create the target F0 input:\n",
    "    uttr_f0_trg = torch.cat((uttr_trg_pad, f0_trg_onehot), dim=-1)\n",
    "    \n",
    "    # -------------------------\n",
    "    # Run Generator Under Different Conditions\n",
    "    # -------------------------\n",
    "    conditions = ['R', 'F', 'U', 'FU', 'RF', 'RU', 'RFU']\n",
    "    spect_vc = []\n",
    "    with torch.no_grad():\n",
    "        for condition in conditions:\n",
    "            if condition == 'R':\n",
    "                x_identic_val, var, mu = G(uttr_f0_org, uttr_trg_pad, emb_org)\n",
    "            elif condition == 'F':\n",
    "                x_identic_val, var, mu = G(uttr_f0_trg, uttr_org_pad, emb_org)\n",
    "            elif condition == 'U':\n",
    "                x_identic_val, var, mu = G(uttr_f0_org, uttr_org_pad, emb_trg)\n",
    "            elif condition == 'RF':\n",
    "                x_identic_val, var, mu = G(uttr_f0_trg, uttr_trg_pad, emb_org)\n",
    "            elif condition == 'RU':\n",
    "                x_identic_val, var, mu = G(uttr_f0_org, uttr_trg_pad, emb_trg)\n",
    "            elif condition == 'FU':\n",
    "                x_identic_val, var, mu = G(uttr_f0_trg, uttr_org_pad, emb_trg)\n",
    "            elif condition == 'RFU':\n",
    "                x_identic_val, var, mu = G(uttr_f0_trg, uttr_trg_pad, emb_trg)\n",
    "            \n",
    "            # Choose output length: if the condition contains 'R', use target length; otherwise, source length.\n",
    "            if 'R' in condition:\n",
    "                uttr_trg_out = x_identic_val[0, :len_trg, :].cpu().numpy()\n",
    "            else:\n",
    "                uttr_trg_out = x_identic_val[0, :len_org, :].cpu().numpy()\n",
    "            \n",
    "            spect_name = f\"{sbmt_i[0]}_{sbmt_j[0]}_{uid_org}_{condition}\"\n",
    "            spect_vc.append((spect_name, uttr_trg_out))\n",
    "    \n",
    "    print(\"Generated spectrograms for conditions:\", [name for name, _ in spect_vc])\n",
    "    \n",
    "    # -------------------------\n",
    "    # Spectrogram-to-Waveform Conversion & Saving\n",
    "    # -------------------------\n",
    "    for spect in spect_vc:\n",
    "        name, spect_data = spect\n",
    "        print(f\"Generating waveform for {name}\")\n",
    "        waveform = wavegen(synth_model, c=spect_data)\n",
    "        out_path = os.path.join(results_dir, f\"{name}.wav\")\n",
    "        soundfile.write(out_path, waveform, samplerate=16000)\n",
    "    \n",
    "    print(f\"Results saved in directory: {results_dir}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
